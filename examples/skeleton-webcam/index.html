<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Skeleton from webcam â€“ Dance Hack</title>
  <style>
    * { box-sizing: border-box; }
    body {
      margin: 0;
      min-height: 100vh;
      background: #1a1a1a;
      color: #eee;
      font-family: system-ui, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 1rem;
    }
    h1 { font-size: 1.25rem; margin: 0 0 0.5rem; }
    p { margin: 0 0 1rem; opacity: 0.8; font-size: 0.9rem; }
    .container {
      position: relative;
      border-radius: 8px;
      overflow: hidden;
      box-shadow: 0 4px 24px rgba(0,0,0,0.4);
    }
    video, canvas {
      display: block;
      width: 100%;
      max-width: 640px;
      height: auto;
      vertical-align: top;
    }
    canvas {
      position: absolute;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    .status { margin-top: 0.5rem; font-size: 0.85rem; color: #8f8; }
    .status.error { color: #f88; }
  </style>
</head>
<body>
  <h1>ðŸ¦´ Skeleton from webcam</h1>
  <p>MediaPipe Pose Landmarker â€“ 33 body points in 2D and 3D. Move and see the skeleton follow.</p>
  <div class="container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>
  <div id="status" class="status">Starting camera &amp; loading modelâ€¦</div>

  <script type="module">
    // MediaPipe Pose Landmarker â€“ skeletal data from webcam (2D + 3D)
    // Load ESM bundle (.mjs); no UMD .js bundle in recent package versions
    const { PoseLandmarker, FilesetResolver } = await import(
      'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/vision_bundle.mjs'
    );

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');

    const POSE_CONNECTIONS = [
      [11, 12], [11, 13], [13, 15], [12, 14], [14, 16],
      [11, 23], [12, 24], [23, 24], [23, 25], [25, 27], [27, 29], [27, 31],
      [24, 26], [26, 28], [28, 30], [28, 32],
      [0, 1], [1, 2], [2, 3], [3, 7], [0, 4], [4, 5], [5, 6], [6, 8],
      [9, 10], [15, 17], [15, 19], [15, 21], [16, 18], [16, 20], [16, 22]
    ];

    function setStatus(msg, isError) {
      statusEl.textContent = msg;
      statusEl.className = 'status' + (isError ? ' error' : '');
    }

    function drawLandmarks(landmarks) {
      if (!landmarks || landmarks.length === 0) return;
      const w = canvas.width;
      const h = canvas.height;
      for (let i = 0; i < POSE_CONNECTIONS.length; i++) {
        const conn = POSE_CONNECTIONS[i];
        const a = landmarks[conn[0]];
        const b = landmarks[conn[1]];
        if (!a || !b) continue;
        ctx.beginPath();
        ctx.moveTo(a.x * w, a.y * h);
        ctx.lineTo(b.x * w, b.y * h);
        ctx.strokeStyle = '#0af';
        ctx.lineWidth = 2;
        ctx.stroke();
      }
      for (let j = 0; j < landmarks.length; j++) {
        const pt = landmarks[j];
        ctx.beginPath();
        ctx.arc(pt.x * w, pt.y * h, 4, 0, Math.PI * 2);
        ctx.fillStyle = '#f0a';
        ctx.fill();
      }
    }

    let poseLandmarker = null;
    let lastVideoTime = -1;

    async function init() {
      try {
        const resolver = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/wasm'
        );
        poseLandmarker = await PoseLandmarker.createFromOptions(resolver, {
          baseOptions: {
            modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task'
          },
          runningMode: 'VIDEO',
          numPoses: 1
        });
      } catch (e) {
        setStatus('Failed to load MediaPipe: ' + e.message, true);
        console.error(e);
        return;
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
        video.srcObject = stream;
        await video.play();
      } catch (e) {
        setStatus('Camera error: ' + e.message, true);
        return;
      }

      video.addEventListener('loadedmetadata', function() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        setStatus('Ready â€“ move in front of the camera');
      });

      function detect() {
        if (!poseLandmarker || video.readyState < 2) {
          requestAnimationFrame(detect);
          return;
        }
        const now = video.currentTime * 1000;
        if (lastVideoTime !== video.currentTime) {
          lastVideoTime = video.currentTime;
          try {
            const result = poseLandmarker.detectForVideo(video, now);
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            if (result.landmarks && result.landmarks[0]) {
              drawLandmarks(result.landmarks[0]);
              // result.worldLandmarks[0] has 3D coords (meters) for driving 3D scenes
            }
          } catch (err) {
            console.warn(err);
          }
        }
        requestAnimationFrame(detect);
      }
      detect();
    }

    init();
  </script>
</body>
</html>
